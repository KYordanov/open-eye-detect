{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed count: 1149\n",
      "Open count: 810\n",
      "Train count: 1559\n"
     ]
    }
   ],
   "source": [
    "# Prepare the DataSet\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "def ShowImgLab(Img_Index):\n",
    "    \n",
    "    print(true_labels[Img_Index])\n",
    "    cv2.imshow('Img', img_arr[Img_Index])\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def shuffle_in_unison(a, b):\n",
    "    \n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "    \n",
    "\n",
    "IMG_WIDTH = 200\n",
    "IMG_HEIGHT = 200\n",
    "CLOSED_COUNT = len(os.listdir('.\\closed_formated'))\n",
    "OPEN_COUNT = len(os.listdir('.\\open_formated'))\n",
    "DEV_SIZE = 300\n",
    "TEST_SIZE = 100\n",
    "TRAIN_SIZE = CLOSED_COUNT + OPEN_COUNT - DEV_SIZE - TEST_SIZE\n",
    "print('Closed count: '+ str(CLOSED_COUNT))\n",
    "print('Open count: '+ str(OPEN_COUNT))\n",
    "print('Train count: '+ str(TRAIN_SIZE))\n",
    "\n",
    "img_arr = np.empty([CLOSED_COUNT + OPEN_COUNT, 1, IMG_WIDTH, IMG_HEIGHT], np.uint8)\n",
    "true_labels = np.empty(CLOSED_COUNT + OPEN_COUNT, np.uint8)\n",
    "\n",
    "# import Closed eyes, one of the classes\n",
    "true_labels[0:CLOSED_COUNT] = 1\n",
    "for dirname, dirnames, filenames in os.walk('.\\closed_formated'):\n",
    "    \n",
    "    for (i, filename) in enumerate(filenames):\n",
    "        image = cv2.imread('.\\closed_formated\\\\'+filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_arr[i] = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "# import Open eyes, one of the classes\n",
    "true_labels[CLOSED_COUNT:CLOSED_COUNT + OPEN_COUNT] = 0\n",
    "for dirname, dirnames, filenames in os.walk('.\\open_formated'):\n",
    "    \n",
    "    for (i, filename) in enumerate(filenames):\n",
    "        image = cv2.imread('.\\open_formated\\\\'+filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Shift after closed \n",
    "        img_arr[i+CLOSED_COUNT] = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "shuffle_in_unison(img_arr, true_labels)\n",
    "\n",
    "X_train = img_arr[0:TRAIN_SIZE]\n",
    "Y_train = true_labels[0:TRAIN_SIZE]\n",
    "\n",
    "X_dev = img_arr[TRAIN_SIZE:TRAIN_SIZE+DEV_SIZE]\n",
    "Y_dev = true_labels[TRAIN_SIZE:TRAIN_SIZE+DEV_SIZE]\n",
    "\n",
    "X_test = img_arr[TRAIN_SIZE+DEV_SIZE:TRAIN_SIZE+DEV_SIZE+TEST_SIZE]\n",
    "Y_test = true_labels[TRAIN_SIZE+DEV_SIZE:TRAIN_SIZE+DEV_SIZE+TEST_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the DataSet\n",
    "for index in range(60,80):\n",
    "    \n",
    "    print(Y_train[index])\n",
    "    cv2.imshow('Img', X_train[index,0])\n",
    "    cv2.waitKey()\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eye(img):\n",
    "    \n",
    "    eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "    \n",
    "    eye_cascade = eye_cascade.detectMultiScale(img)\n",
    "    \n",
    "    for (x,y,w,h) in eye_cascade:\n",
    "        #img = cv2.rectangle(img, (x,y),(x+w,y+h),(255,0,0),2)\n",
    "        \n",
    "        img = img[y:y+h,x:x+w]\n",
    "        break\n",
    "        \n",
    "    img = cv2.resize(img, (30, 30), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(430,450):\n",
    "    cv2.imshow('Img', X_train[index,0])\n",
    "    cv2.waitKey()\n",
    "    cv2.imshow('Img', extract_eye(X_train[index,0]))\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eye_train = np.empty([TRAIN_SIZE, 1, 30, 30], np.uint8)\n",
    "X_eye_dev = np.empty([DEV_SIZE, 1, 30, 30], np.uint8)\n",
    "\n",
    "for (i, i_train) in enumerate(X_train):\n",
    "    X_eye_train[i] = extract_eye(i_train[0])\n",
    "    \n",
    "for (i, i_dev) in enumerate(X_dev):\n",
    "    X_eye_dev[i] = extract_eye(i_dev[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check the DataSet\n",
    "for index in range(80,100):\n",
    "    \n",
    "    print(Y_dev[index])\n",
    "    cv2.imshow('Img', X_dev[index,0])\n",
    "    cv2.waitKey()\n",
    "    cv2.imshow('Img', X_eye_dev[index,0])\n",
    "    cv2.waitKey()\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "def OpenEyeDetect(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the OpenEyeDetect.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    #X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n",
    "    #X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    #X = Activation('relu')(X)\n",
    "    # MAXPOOL\n",
    "    #X = MaxPooling2D((2, 2), name='max_pool0')(X)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (5, 5), strides=(1, 1), name='conv1')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(64, (5, 5), strides=(1, 1), name='conv2')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool2')(X)\n",
    "    \n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs=X_input, outputs=X, name='OpenEyeDetect')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_closedEyesModel = OpenEyeDetect(X_eye_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_closedEyesModel.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.2478 - acc: 0.8993     \n",
      "Epoch 2/15\n",
      "1559/1559 [==============================] - 0s - loss: 0.2218 - acc: 0.9083     \n",
      "Epoch 3/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.2209 - acc: 0.9121     \n",
      "Epoch 4/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.2117 - acc: 0.9243     \n",
      "Epoch 5/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.2224 - acc: 0.9153     \n",
      "Epoch 6/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1899 - acc: 0.9262     \n",
      "Epoch 7/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1720 - acc: 0.9359     \n",
      "Epoch 8/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1911 - acc: 0.9269     \n",
      "Epoch 9/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1688 - acc: 0.9352     \n",
      "Epoch 10/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1502 - acc: 0.9468     \n",
      "Epoch 11/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1569 - acc: 0.9461     \n",
      "Epoch 12/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1630 - acc: 0.9436     \n",
      "Epoch 13/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1582 - acc: 0.9339     \n",
      "Epoch 14/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1359 - acc: 0.9545     \n",
      "Epoch 15/15\n",
      "1559/1559 [==============================] - 1s - loss: 0.1542 - acc: 0.9416     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de68d8ff28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_closedEyesModel.fit(X_eye_train, Y_train, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s     \n",
      "\n",
      "Loss = 0.229616438746\n",
      "Test Accuracy = 0.920000000795\n"
     ]
    }
   ],
   "source": [
    "preds = ins_closedEyesModel.evaluate(X_eye_dev, Y_dev, batch_size=32, verbose=1, sample_weight=None)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99639624]]\n",
      "[[ 0.00150032]]\n",
      "[[ 0.99992836]]\n",
      "[[ 0.89635199]]\n",
      "[[ 0.99999475]]\n",
      "[[ 0.22430634]]\n",
      "[[ 0.47727466]]\n",
      "[[ 0.95485944]]\n",
      "[[ 0.98045337]]\n",
      "[[ 0.06080761]]\n",
      "[[ 0.22928509]]\n",
      "[[ 0.97302419]]\n",
      "[[ 0.01318093]]\n",
      "[[ 0.00010067]]\n",
      "[[ 0.87892455]]\n",
      "[[ 0.9999994]]\n",
      "[[ 0.99784315]]\n",
      "[[ 0.99931812]]\n",
      "[[ 0.82177544]]\n",
      "[[ 0.17663963]]\n"
     ]
    }
   ],
   "source": [
    "for index in range(60, 80):\n",
    "    print(ins_closedEyesModel.predict(X_eye_dev[index:index+1]))\n",
    "    cv2.imshow('Img', X_dev[index,0])\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1, 30, 30)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 1, 36, 36)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 32, 32, 32)        832       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 32, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 64, 12, 12)        51264     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 64, 12, 12)        48        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 64, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 2305      \n",
      "=================================================================\n",
      "Total params: 54,577\n",
      "Trainable params: 54,489\n",
      "Non-trainable params: 88\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ins_closedEyesModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_closedEyesModel.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "ins_closedEyesModel = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_closedEyesModel = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.empty([1, 1, IMG_WIDTH, IMG_HEIGHT], np.uint8)\n",
    "image = cv2.imread('zuc.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "img_arr[0,0] = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "print(ins_closedEyesModel.predict(img_arr))\n",
    "cv2.imshow('Img', img_arr[0,0])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch(image):\n",
    "    img_arr = np.empty([1, 1, 30, 30], np.uint8)\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_arr[0,0] = extract_eye(img_gray)\n",
    "    pred = ins_closedEyesModel.predict(img_arr)\n",
    "    #cv2.putText(img_arr[0,0], str(pred), (0,50), cv2.FONT_HERSHEY_COMPLEX, 1, (100,170,0), 2)\n",
    "    if pred < 0.5 :\n",
    "        cv2.putText(image, 'Open', (0,50), cv2.FONT_HERSHEY_COMPLEX, 2, (100,170,0), 3)\n",
    "    else :\n",
    "        cv2.putText(image, 'Close', (0,50), cv2.FONT_HERSHEY_COMPLEX, 2, (100,170,0), 3)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize webcam, cap is the object provided by VideoCapture\n",
    "# It contains a boolean indicating if it was sucessful (ret)\n",
    "# It also contains the images collected from the webcam (frame)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Our Live Sketcher', sketch(frame))\n",
    "    #cv2.imshow('Our Live Sketcher', frame)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "# Release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store images from VideoCapture\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Our Live Sketcher', frame)\n",
    "    cv2.imwrite('My_data\\\\output'+str(i)+'.jpg', frame)\n",
    "    i += 1\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "\n",
    "# Release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, dirnames, filenames in os.walk('.\\My_data'):\n",
    "\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread('.\\My_data\\\\'+filename)\n",
    "        cv2.imshow('Check Result', sketch(image))\n",
    "        cv2.waitKey()\n",
    "\n",
    "# Close windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
